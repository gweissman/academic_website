[{"authors":["admin"],"categories":null,"content":"I am a pulmonary and critical care physician at the University of Pennsylvania Perelman School of Medicine, and core faculty at the Palliative and Advanced Illness Research (PAIR) Center. My research interests include clinical informatics, natural language processing, machine learning, population health, and pragmatic trials. I am also a Senior Fellow at the Leonard Davis Institute of Health Economics.\n","date":-62135596800,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1556069473,"objectID":"598b63dd58b43bce02403646f240cd3c","permalink":"/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"author","summary":"I am a pulmonary and critical care physician at the University of Pennsylvania Perelman School of Medicine, and core faculty at the Palliative and Advanced Illness Research (PAIR) Center. My research interests include clinical informatics, natural language processing, machine learning, population health, and pragmatic trials. I am also a Senior Fellow at the Leonard Davis Institute of Health Economics.","tags":null,"title":"Gary Weissman","type":"author"},{"authors":[],"categories":null,"content":" Click on the Slides button above to view the built-in slides feature.   Slides can be added in a few ways:\n Create slides using Academic\u0026rsquo;s Slides feature and link using slides parameter in the front matter of the talk file Upload an existing slide deck to static/ and link using url_slides parameter in the front matter of the talk file Embed your slides (e.g. Google Slides) or presentation video on this page using shortcodes.  Further talk details can easily be added to this page using Markdown and $\\rm \\LaTeX$ math code.\n","date":1906563600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1556067994,"objectID":"96344c08df50a1b693cc40432115cbe3","permalink":"/talk/example/","publishdate":"2017-01-01T00:00:00-05:00","relpermalink":"/talk/example/","section":"talk","summary":"An example talk using Academic's Markdown slides feature.","tags":[],"title":"Example Talk","type":"talk"},{"authors":null,"categories":["brier score","predictive modeling"],"content":" Background The Brier Score is a composite measure of discrimination and calibration for a prediction model. The Brier Score is defined as\n\\[ BS = \\frac{1}{N} \\sum (y_i - \\hat y_i)^2, \\]\nwhere \\(N\\) is the number of observations, \\(y_i\\) is the observed outcome, either 0 or 1, and \\(\\hat y_i\\) is the predicted probability for the \\(i\\)th observation. Let’s create an R function calculate the Brier Score:\nbrier_score \u0026lt;- function(obs, pred) { mean((obs - pred)^2) } The scaled Brier Score accounts for the event rate and provides an immediate comparison to an uninformative model that is equivalent to “just guess the event rate.” An intuitive way to define the scaled Brier Score (also called the “Brier skill score”) is\n\\[ BS_{scaled} = 1 - \\frac{BS}{BS_{max}}, \\]\nwhere \\(BS_{max} = \\frac{1}{N} \\sum (y_i - \\bar y_i)^2\\) and \\(\\bar y_i\\) is the event rate among the observed outcome.\n My confusion This formulation of the scaled Brier Score makes intuitive sense to me and is how I go about calculating it in practice. However, two other distinct formulations have been proposed for calculating \\(BS_{max}\\) that — at least to the limits of my algebraic skills – differ. Thus, here I proposed a numeric investigation of these different definitions to see if they are indeed equivalent.\n Definition 1 This is the intuitive definition to which I am accustomed, and is made explicit here: https://www.ncbi.nlm.nih.gov/pubmed/29713202\n\\[ BS_{scaled} = 1 - \\frac{\\frac{1}{N} \\sum (y_i - \\hat y_i)^2}{\\frac{1}{N} \\sum (y_i - \\bar y_i)^2}. \\]\nLet’s create an R function to calculate this value.\nscaled_brier_score_1 \u0026lt;- function(obs, pred) { 1 - (brier_score(obs, pred) / brier_score(obs, mean(obs))) }  Definition 2 A second formulation of the scaled Brier Score is defined with a slightly different definition of \\(BS_{max}\\), which is in this case described in https://www.ncbi.nlm.nih.gov/pubmed/20010215\n\\[ BS_{max} = \\hat p \\times (1 - \\hat p). \\]\nLet’s create an R function to calculate this measure.\nscaled_brier_score_2 \u0026lt;- function(obs, pred) { 1 - (brier_score(obs, pred) / (mean(obs) * (1 - mean(obs)))) }  Definition 3 A third formulation of the scaled Brier Score is defined with a slightly different definition of \\(BS_{max}\\), which is in this case described in https://www.ncbi.nlm.nih.gov/pubmed/22961910\n\\[ BS_{max} = \\hat p \\times (1 - \\hat p)^2 + (1 - \\hat p) \\times \\hat p^2. \\]\nLet’s create an R function to calculate this measure.\nscaled_brier_score_3 \u0026lt;- function(obs, pred) { 1 - (brier_score(obs, pred) / (mean(obs) * (1 - mean(obs))^2 + (1 - mean(obs)) * mean(obs)^2)) }  Build a model Let’s build a sample model based on the UCI abalone data (https://archive.ics.uci.edu/ml/datasets/Abalone).\n# get data df \u0026lt;- read.csv(\u0026#39;https://archive.ics.uci.edu/ml/machine-learning-databases/abalone/abalone.data\u0026#39;) names(df) \u0026lt;- c(\u0026#39;sex\u0026#39;, \u0026#39;length\u0026#39;, \u0026#39;diameter\u0026#39;, \u0026#39;height\u0026#39;, \u0026#39;weight_whole\u0026#39;, \u0026#39;weight_shucked\u0026#39;, \u0026#39;weight_viscera\u0026#39;, \u0026#39;weight_shell\u0026#39;, \u0026#39;rings\u0026#39;) # inspect data knitr::kable(head(df))   sex length diameter height weight_whole weight_shucked weight_viscera weight_shell rings    M 0.350 0.265 0.090 0.2255 0.0995 0.0485 0.070 7  F 0.530 0.420 0.135 0.6770 0.2565 0.1415 0.210 9  M 0.440 0.365 0.125 0.5160 0.2155 0.1140 0.155 10  I 0.330 0.255 0.080 0.2050 0.0895 0.0395 0.055 7  I 0.425 0.300 0.095 0.3515 0.1410 0.0775 0.120 8  F 0.530 0.415 0.150 0.7775 0.2370 0.1415 0.330 20    # Let\u0026#39;s predict whether or not an abalone will have \u0026gt; 10 rings m1 \u0026lt;- glm(I(rings \u0026gt; 10) ~ ., data = df, family = binomial) preds_m1 \u0026lt;- predict(m1, type = \u0026#39;response\u0026#39;) # And another model with severe class imablance m2 \u0026lt;- glm(I(rings \u0026gt; 3) ~ ., data = df, family = binomial) ## Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred preds_m2 \u0026lt;- predict(m2, type = \u0026#39;response\u0026#39;)  Score the model # ---------- Model 1 # Calculate the Brier Score brier_score(df$rings \u0026gt; 10, preds_m1) ## [1] 0.1479862 # Calculate each type of scaled Brier Score scaled_brier_score_1(df$rings \u0026gt; 10, preds_m1) ## [1] 0.3462507 scaled_brier_score_2(df$rings \u0026gt; 10, preds_m1) ## [1] 0.3462507 scaled_brier_score_3(df$rings \u0026gt; 10, preds_m1) ## [1] 0.3462507 # ---------- Model 2 # Calculate the Brier Score brier_score(df$rings \u0026gt; 3, preds_m2) ## [1] 0.002690905 # Calculate each type of scaled Brier Score scaled_brier_score_1(df$rings \u0026gt; 3, preds_m2) ## [1] 0.3362851 scaled_brier_score_2(df$rings \u0026gt; 3, preds_m2) ## [1] 0.3362851 scaled_brier_score_3(df$rings \u0026gt; 3, preds_m2) ## [1] 0.3362851  ","date":1555977600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1556067994,"objectID":"84a76f3c896e4797207fe1ff0ec5b2d3","permalink":"/post/evaluating-the-equivalence-of-different-formulations-of-the-scaled-brier-score/","publishdate":"2019-04-23T00:00:00Z","relpermalink":"/post/evaluating-the-equivalence-of-different-formulations-of-the-scaled-brier-score/","section":"post","summary":"Background The Brier Score is a composite measure of discrimination and calibration for a prediction model. The Brier Score is defined as\n\\[ BS = \\frac{1}{N} \\sum (y_i - \\hat y_i)^2, \\]\nwhere \\(N\\) is the number of observations, \\(y_i\\) is the observed outcome, either 0 or 1, and \\(\\hat y_i\\) is the predicted probability for the \\(i\\)th observation. Let’s create an R function calculate the Brier Score:\nbrier_score \u0026lt;- function(obs, pred) { mean((obs - pred)^2) } The scaled Brier Score accounts for the event rate and provides an immediate comparison to an uninformative model that is equivalent to “just guess the event rate.","tags":[],"title":"Evaluating the equivalence of different formulations of the scaled Brier score","type":"post"},{"authors":["Gary Weissman"],"categories":null,"content":" Supplementary notes can be added here, including code and math.   ","date":1554609600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1556067994,"objectID":"557dc08fd4b672a0c08e0a8cf0c9ff7d","permalink":"/publication/preprint/","publishdate":"2019-04-07T00:00:00-04:00","relpermalink":"/publication/preprint/","section":"publication","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":["Source Themes"],"title":"An example preprint / working paper","type":"publication"},{"authors":null,"categories":["keras","rnn","python"],"content":"Recurrent neural networks and their variants are helpful for extracting information from time series. Here\u0026rsquo;s an example using sample data to get up and running.\nI found the following other websites helpful in reading up on code examples:\n https://machinelearningmastery.com/multi-step-time-series-forecasting-long-short-term-memory-networks-python/ https://github.com/rstudio/keras/blob/master/vignettes/examples/lstm_benchmark.py https://github.com/jaungiers/LSTM-Neural-Network-for-Time-Series-Prediction/blob/master/lstm.py  # setup import numpy as np import pandas as pd import math import matplotlib.pyplot as plt from keras.models import Sequential from keras.layers import Dense, Dropout, SimpleRNN from keras.callbacks import EarlyStopping from sklearn.model_selection import train_test_split # make a sample multivariable time series - not autoregressive # generate a random walk def random_walk(steps, scale = 1): w = np.zeros(steps) for x in range(1,steps): w[x] = w[x-1] + scale * np.random.normal() return(w) time_steps = 5000 data = pd.DataFrame({'x' : range(time_steps), 'y' : np.arange(time_steps) ** (1/2) + random_walk(time_steps) }) data = data.assign(z = np.log(data.x+1) + 0.3 * data.y) data_mat = np.array(data)  Take a look at the data.\nplt.subplot(2,1,1) plt.plot(data_mat[:,0], data_mat[:,2], c = 'goldenrod') plt.margins(0.05) plt.subplot(2,1,2) plt.plot(data_mat[:,1], data_mat[:,2], c = 'firebrick') plt.margins(0.05) plt.show()  # split into samples (sliding time windows) samples = list() target = list() length = 50 # step over the 5,000 in jumps of length for i in range(time_steps - length - 1): # grab from i to i + length sample = data_mat[i:i+length,:2] outcome = data_mat[i+length+1,2] target.append(outcome) samples.append(sample) # split out a test set test_size = 1000 x_test_mat = np.dstack(samples[-test_size:]) x_test_3d_final = np.moveaxis(x_test_mat, [0, 1, 2], [1, 2, 0] ) # The RNN needs data with the format of [samples, time steps, features]. # Here, we have N samples, 50 time steps per sample, and 2 features data_mat_stacked = np.dstack(samples[:-test_size]) data_mat_3d_final = np.moveaxis(data_mat_stacked, [0, 1, 2], [1, 2, 0] ) # and fix up the target target_arr = np.array(target[:-test_size]) # now build the RNN model = Sequential() model.add(SimpleRNN(128, input_shape = (data_mat_3d_final.shape[1], data_mat_3d_final.shape[2]), activation = 'relu')) model.add(Dropout(0.1)) model.add(Dense(64, activation = 'relu')) model.add(Dropout(0.1)) model.add(Dense(16, activation = 'relu')) model.add(Dropout(0.1)) model.add(Dense(1, activation='linear')) # monitor validation progress early = EarlyStopping(monitor = \u0026quot;val_loss\u0026quot;, mode = \u0026quot;min\u0026quot;, patience = 7) callbacks_list = [early] model.compile(loss = 'mean_squared_error', optimizer = 'adam', metrics = ['mse']) # and train the model history = model.fit(data_mat_3d_final, target_arr, epochs=50, batch_size=25, verbose=2, validation_split = 0.20, callbacks = callbacks_list) # plot history plt.plot(history.history['loss'], label='train') plt.plot(history.history['val_loss'], label='val') plt.legend() plt.show()  # get predictions train_predictions = model.predict(data_mat_3d_final) test_predictions = model.predict(x_test_3d_final) # plot predictions vs actual plt.plot(data['x'], data['z'], c = 'goldenrod', label = 'data') plt.plot(data.iloc[(length+1):-test_size]['x'], train_predictions, c = 'navy', label = 'train') plt.plot(data.iloc[-test_size:]['x'], test_predictions, c = 'firebrick', label = 'test') plt.legend(loc='best') plt.show()  Not bad!\n","date":1518652800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1556068367,"objectID":"3b658f449f2e66d6f77fa54c9979fa28","permalink":"/post/building-a-recurrent-neural-network-to-predict-time-series-data-with-keras-in-python/","publishdate":"2018-02-15T00:00:00Z","relpermalink":"/post/building-a-recurrent-neural-network-to-predict-time-series-data-with-keras-in-python/","section":"post","summary":"Recurrent neural networks and their variants are helpful for extracting information from time series. Here\u0026rsquo;s an example using sample data to get up and running.\nI found the following other websites helpful in reading up on code examples:\n https://machinelearningmastery.com/multi-step-time-series-forecasting-long-short-term-memory-networks-python/ https://github.com/rstudio/keras/blob/master/vignettes/examples/lstm_benchmark.py https://github.com/jaungiers/LSTM-Neural-Network-for-Time-Series-Prediction/blob/master/lstm.py  # setup import numpy as np import pandas as pd import math import matplotlib.pyplot as plt from keras.models import Sequential from keras.layers import Dense, Dropout, SimpleRNN from keras.","tags":[],"title":"Building a recurrent neural network to predict time-series data with Keras in Python","type":"post"},{"authors":null,"categories":["R","maps"],"content":" Every now and then it is useful to make a map. In times of political uncertainty, data can light a path forward. Your local elected officals may be interested in data, too, and how they impact policy (and re-election, of course).\nLet\u0026rsquo;s say you wanted to know if people are still enrolling the Healthcare.gov plans in your local State Senatorial district. It\u0026rsquo;s quite difficult to find data broken up at this level but zip codes can approximate such an approach. Here\u0026rsquo;s information from Pennsylvania 26th Senatorial District.\nMarketplace enrollment Using publicly available data from the Centers for Medicare \u0026amp; Medicaid Services, this file includes data by zip code on enrollment through HealthCare.gov The data description reads:\n\u0026ldquo;2017 OEP ZIP Code-Level Public Use File: This ZIP code and APTC PUF includes total health plan selections, the count of consumers with APTC, and average APTC among consumers with APTC between November 1, 2016 and January 31, 2017. This PUF only includes data for the 39 states that used the HealthCare.gov platform in 2017.\u0026rdquo;\n# setup require(zipcode) library(readxl) require(dplyr) require(choroplethrZip) require(magrittr) data(zipcode) # download and extract this file: https://www.cms.gov/Research-Statistics-Data-and-Systems/Statistics-Trends-and-Reports/Marketplace-Products/Plan_Selection_ZIP.html dt \u0026lt;- read_excel('2017_OEP_ZIP_Code-Level_Public_Use_File.xlsx', sheet = 4) # approximating the 26th district zips_26thsenate \u0026lt;- c('19029', '19081', '19082', '19078', '19036', '19033', '19070', '19018', '19026', '19064', '19063', '19008', '19073', '19355', '19301', '19050') dt %\u0026lt;\u0026gt;% select(ZipCode = 'ZIP Code', Enrollees = 'Total Number of Consumers Who Have Selected a Marketplace Plan') %\u0026gt;% mutate(Enrollees = as.integer(Enrollees)) %\u0026gt;% filter(ZipCode %in% zips_26thsenate) %\u0026gt;% left_join(zipcode, by = c('ZipCode' = 'zip'))  Summarize the results by zip:\ndt %\u0026gt;% select(ZipCode, City = city, Enrollees) %\u0026gt;% arrange(desc(Enrollees)) %\u0026gt;% knitr::kable()  And plot the output:\nzipmap \u0026lt;- dt %\u0026gt;% select(value = Enrollees, region = ZipCode) %\u0026gt;% zip_choropleth(zip_zoom = zips_26thsenate, reference_map = TRUE, title = 'Healthcare.gov enrollees November 1, 2016 - January 21, 2017') plot(zipmap)  ","date":1500249600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1556068521,"objectID":"e4360c82309ef5cfe0cc264456f46907","permalink":"/post/making-choropleth-maps-by-zip-code/","publishdate":"2017-07-17T00:00:00Z","relpermalink":"/post/making-choropleth-maps-by-zip-code/","section":"post","summary":"Every now and then it is useful to make a map. In times of political uncertainty, data can light a path forward. Your local elected officals may be interested in data, too, and how they impact policy (and re-election, of course).\nLet\u0026rsquo;s say you wanted to know if people are still enrolling the Healthcare.gov plans in your local State Senatorial district. It\u0026rsquo;s quite difficult to find data broken up at this level but zip codes can approximate such an approach.","tags":[],"title":"Making choropleth maps by zip code","type":"post"},{"authors":null,"categories":["babelgraph","blog","social network analysis"],"content":"Here\u0026rsquo;s the blog post originally posted on babelgraph.org on March 25, 2011. The relevant hyperlinks and igraph code have been updated to reflect the current state of things. The edgelist, despite many more intervening seasons, and thus many more romances, has not been updated. Here is a nice walkthrough of ERGMs based on this post \u0026ndash; sorry for the broken link, Ben.\nThis all began with an introductory presentation about social network analysis to a group of medical students. What better way to grab their attention than with attractive, fake doctors having sex on television? Naturally this led to the dense network of sexual contacts between characters on the Grey’s Anatomy television show. After viewing many hours of previous episodes and exploring fan pages (especially here for an early attempt at a graph representation of sexual contacts), I was able to come up with an extensive but by no means exhaustive list of contacts. The edge list is available here.\nThis example uses the igraph package for R, both free to download. First we create the graph, give it a layout, and plot.\nlibrary(igraph) ga.data \u0026lt;- read.csv('ga_edgelist.csv', header = TRUE) g \u0026lt;- graph.data.frame(ga.data, directed=FALSE) summary(g) g$layout \u0026lt;- layout.fruchterman.reingold(g) plot(g)  Without knowing who is represented by each vertex, what can you deduce from the graph? From a public health perspective, if you could test one person for sexually transmitted infections (STIs), who would it be? If you could provide counseling and a free box of condoms to one person, who would it be? If you knew that an epidemic was spreading through this network, who would you want to be to best avoid it?\nNow let’s make the visualization a little more interesting. First we can remove the labels for now, and then change the size of the vertex to represent the degree, or degree centrality, corresponding to the number of partners of each vertex. In the context of transmissible infections, this would indicate the number of people a person could infect or be infected by through sexual contact.\nV(g)$label \u0026lt;- NA # remove labels for now V(g)$size \u0026lt;- degree(g) * 2 # multiply by 2 for scale plot(g)  This tells us about the absolute number of partners, but not much about the relative position within the network. Let’s examine two types of centrality: closeness and betweenness. The closeness centrality is the average shortest path from one vertex to every other on the graph. A high number indicates that a vertex is quickly reachable by the majority of vertices in the graph, while a low number indicates that the vertex is far from most other vertices on the graph. We can calculate the centrality and then rescale the values to create a color scheme to visualize the relative differences.\nclo \u0026lt;- closeness(g) # rescale values to match the elements of a color vector clo.score \u0026lt;- round( (clo - min(clo)) * length(clo) / max(clo) ) + 1 # create color vector, use rev to make red \u0026quot;hot\u0026quot; clo.colors \u0026lt;- rev(heat.colors(max(clo.score))) V(g)$color \u0026lt;- clo.colors[ clo.score ] plot(g)  It appears there are a few vertices on the red “hot” end of the spectrum, and a few at the “cold” end. Next we do the same for each vertex to calculate the betweenness centrality, which is the number of shortest paths on the network that pass through the vertex. Vertices with high betweenness centrality might be thought of as serving a gatekeeper role in mediating the shortest connections between other vertices.\nbtw \u0026lt;- betweenness(g) btw.score \u0026lt;- round(btw) + 1 btw.colors \u0026lt;- rev(heat.colors(max(btw.score))) V(g)$color \u0026lt;- btw.colors[ btw.score ] plot(g)  This last graph of betweenness indicates slightly more variation among the likely suspects, while the analysis of closeness centrality demonstrated less variation. Why?\nA useful technique in social network analysis is the use of community finding algorithms. Here we use the implementation of the Girvan-Newman algorithm (paper here) to detect the underlying community structure of the graph. We will iterate through each merge to determine which cut produces the maximum modularity, and then use that number to calculate the groups.\n# this section has been substantially revised to reflect the # newer version of igraph which does GN membership easily V(g)$color \u0026lt;- membership(cluster_edge_betweenness(g)) V(g)$size \u0026lt;- 15 # reset to default size plot(g) # those new default igraph colors are so much nicer, too!  Once you see the graph with names, it is interesting to note the breaks in connectivity around race and age (I guess you have to know the TV characters to appreciate this ;) ) So before seeing the names, back to the original question. Who would you test? Who would you counsel? Who would you vaccinate? Who would you rather be?\nAnd the winners are…\nV(g)$color \u0026lt;- 'grey' V(g)$label \u0026lt;- V(g)$name V(g)$label.cex \u0026lt;- 0.7 # rescale the text size of the label plot(g)  ","date":1497484800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1556067994,"objectID":"37fc9011f34f7a12f94f2f3bbeac8aeb","permalink":"/post/grey-s-anatomy-network-of-sexual-relations/","publishdate":"2017-06-15T00:00:00Z","relpermalink":"/post/grey-s-anatomy-network-of-sexual-relations/","section":"post","summary":"Here\u0026rsquo;s the blog post originally posted on babelgraph.org on March 25, 2011. The relevant hyperlinks and igraph code have been updated to reflect the current state of things. The edgelist, despite many more intervening seasons, and thus many more romances, has not been updated. Here is a nice walkthrough of ERGMs based on this post \u0026ndash; sorry for the broken link, Ben.\nThis all began with an introductory presentation about social network analysis to a group of medical students.","tags":[],"title":"Grey’s Anatomy Network of Sexual Relations","type":"post"},{"authors":null,"categories":["babelgraph","blog","meta"],"content":"Welcome to this blog, which is the new home for thoughts and technical things. As babelgraph.org has been retired, you can still get the code at:\nBabelGraph Alpha\nOver time I will try to migrate the old blog posts (mostly dealing with network analyses and C++ using R) to here along with the very informative user comments, and updates.\nFor old time\u0026rsquo;s sake, here is the old thumbnail gallery from the BabelGraph Alpha release (mixed Linux and Mac screenshots). A beautiful sight!\n","date":1497484800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1497484800,"objectID":"1c57548da8a1a34ec04e52bb69accdb6","permalink":"/post/welcome-to-the-blog/","publishdate":"2017-06-15T00:00:00Z","relpermalink":"/post/welcome-to-the-blog/","section":"post","summary":"Welcome to this blog, which is the new home for thoughts and technical things. As babelgraph.org has been retired, you can still get the code at:\nBabelGraph Alpha\nOver time I will try to migrate the old blog posts (mostly dealing with network analyses and C++ using R) to here along with the very informative user comments, and updates.\nFor old time\u0026rsquo;s sake, here is the old thumbnail gallery from the BabelGraph Alpha release (mixed Linux and Mac screenshots).","tags":[],"title":"Welcome to the blog!","type":"post"},{"authors":["Gary Weissman"],"categories":null,"content":" Supplementary notes can be added here, including code and math.   ","date":1441080000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1556067994,"objectID":"966884cc0d8ac9e31fab966c4534e973","permalink":"/publication/journal-article/","publishdate":"2015-09-01T00:00:00-04:00","relpermalink":"/publication/journal-article/","section":"publication","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":["Source Themes"],"title":"An example journal article","type":"publication"},{"authors":["Gary Weissman","Robert Ford"],"categories":null,"content":" Supplementary notes can be added here, including code and math.   ","date":1372651200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1556067994,"objectID":"69425fb10d4db090cfbd46854715582c","permalink":"/publication/conference-paper/","publishdate":"2013-07-01T00:00:00-04:00","relpermalink":"/publication/conference-paper/","section":"publication","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":["Source Themes"],"title":"An example conference paper","type":"publication"},{"authors":null,"categories":null,"content":" Welcome to Slides Academic\nFeatures  Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides  Controls  Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export: E  Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026quot;blueberry\u0026quot; if porridge == \u0026quot;blueberry\u0026quot;: print(\u0026quot;Eating...\u0026quot;)  Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = \\;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\nFragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}}  Press Space to play!\nOne  Two  Three \nA fragment can accept two optional parameters:\n class: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears  Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}}  Press the S key to view the speaker notes!\n Only the speaker can read these notes Press S key to view   Themes  black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links   night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links  Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026quot;/img/boards.jpg\u0026quot; \u0026gt;}} {{\u0026lt; slide background-color=\u0026quot;#0000FF\u0026quot; \u0026gt;}} {{\u0026lt; slide class=\u0026quot;my-style\u0026quot; \u0026gt;}}  Custom CSS Example Let\u0026rsquo;s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; }  Questions? Ask\nDocumentation\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1556067994,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"/slides/example/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/slides/example/","section":"slides","summary":"Welcome to Slides Academic\nFeatures  Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides  Controls  Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export: E  Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026quot;blueberry\u0026quot; if porridge == \u0026quot;blueberry\u0026quot;: print(\u0026quot;Eating...\u0026quot;)  Math In-line math: $x + y = z$","tags":null,"title":"Slides","type":"slides"}]